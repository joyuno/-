{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMWikK4kXK9F50zePff/FhW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joyuno/-/blob/main/Big_Data_Derby_2022(used_car)(%ED%95%84%EC%82%AC).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U autogluon"
      ],
      "metadata": {
        "id": "d2F9JB8a8g1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AutoGluon의 TabularPredictor를 임포트하여 자동화된 예측 모델링을 수행할 수 있도록 함\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# 경고 메시지를 무시하도록 설정\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#pandas와 numpy 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 시각화 작업을 위한 matplotlib 임포트\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 문자열에서 숫자를 추출하기 위한 정규표현식 임포트\n",
        "import re\n",
        "\n",
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')\n",
        "\n",
        "# 추가적인 원본 데이터셋을 불러옴 (중고차 가격 예측 데이터셋)\n",
        "Original = pd.read_csv('/content/used_cars.csv')\n",
        "print(Original)\n",
        "# 'milage'와 'price' 컬럼에 포함된 $빼고 KM빼고 숫자만 추출하여 정수형으로 변환\n",
        "Original[['milage', 'price']] = Original[['milage', 'price']].map(\n",
        "    lambda x: int(''.join(re.findall(r'\\d+', x))))\n",
        "\n",
        "# LightGBM, CatBoost, XGBoost 모델을 위한 임포트 (회귀 모델)\n",
        "import lightgbm as lgb\n",
        "from lightgbm import log_evaluation, early_stopping\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# 난수 생성을 위한 random 임포트\n",
        "import random\n",
        "\n",
        "# Support Vector Regression(SVR) 모델을 위한 임포트\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# 모델 성능 평가를 위한 MSE 임포트\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# K-fold 교차 검증을 위한 KFold 임포트\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# AutoGluon의 TabularPredictor: 모델 예측을 자동화 모델 전처리x 모델 선택 x 알아서 척척\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "##원본 데이터 original은 실제 데이터이고 train과 test 모두 중고차 가격 예측 데이터 세트에서 훈련된 딥러닝 모델을 통해 생성된  데이터 이다.\n",
        "# 목적은 원본데이터를 같이 넢고 학습했을때 성능이 향상되는지이다."
      ],
      "metadata": {
        "id": "1oU-w2QH8gyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.head(3))\n",
        "print(train.info())\n",
        "print(test.info())"
      ],
      "metadata": {
        "id": "EdpKpzAO8ghT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(columns=['id'], inplace=True)\n",
        "test.drop(columns=['id'], inplace=True) # 필요없는 칼럼 제거\n",
        "\n",
        "\n",
        "train = pd.concat([train, Original], ignore_index=True) # [train,original] 결합"
      ],
      "metadata": {
        "id": "AS2TOJJfPDmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## feature engineering\n",
        "# age 피처 더 명확하게 살리기\n",
        "def extract_age_features(df):\n",
        "    current_year = 2024 # 현재 년도\n",
        "\n",
        "    # Vehicle_Age: 차량 연령 계산, 년도와 같은 범주형 변수를 수치화 시킴\n",
        "    df['Vehicle_Age'] = current_year - df['model_year']\n",
        "\n",
        "    # Mileage_per_Year: 연간 주행 거리 계산\n",
        "    df['Mileage_per_Year'] = df['milage'] / df['Vehicle_Age']\n",
        "\n",
        "    # milage_with_age: 같은 연식 차량들의 평균 마일리지 계산\n",
        "    df['milage_with_age'] = df.groupby('Vehicle_Age')['milage'].transform('mean')\n",
        "    #df.groupby('Vehicle_Age')['milage'].mean()은 각 Vehicle_Age 값에 대해 평균 마일리지만 계산\n",
        "    # 그러나 이 결과는 원본 데이터와 일치하지 않기 때문에\n",
        "    # 마일리지 값을 각 행에 맞게 다시 분배하려면 transform\n",
        "    # transform은 각 그룹에 대해 함수를 적용한 후 결과를 원본 데이터의 각 행에 맞게 반복해서 반환\n",
        "    # Mileage_per_Year_with_age: 같은 연식 차량들의 평균 연간 주행 거리 계산\n",
        "    df['Mileage_per_Year_with_age'] = df.groupby('Vehicle_Age')['Mileage_per_Year'].transform('mean')\n",
        "\n",
        "    return df\n",
        "# 브랜드 피처 살리기\n",
        "def extract_other_features(df):\n",
        "    # 고급 브랜드 리스트\n",
        "    luxury_brands = ['Mercedes-Benz', 'BMW', 'Audi', 'Porsche', 'Land',\n",
        "                    'Lexus', 'Jaguar', 'Bentley', 'Maserati', 'Lamborghini',\n",
        "                    'Rolls-Royce', 'Ferrari', 'McLaren', 'Aston', 'Maybach']\n",
        "\n",
        "    # 브랜드가 고급 브랜드 리스트에 포함되면 1, 아니면 0\n",
        "    df['Is_Luxury_Brand'] = df['brand'].apply(lambda x: 1 if x in luxury_brands else 0)\n",
        "\n",
        "    return df\n",
        "# 함수 적용\n",
        "train = extract_age_features(train)\n",
        "test = extract_age_features(test)\n",
        "\n",
        "train = extract_other_features(train)\n",
        "test = extract_other_features(test)\n"
      ],
      "metadata": {
        "id": "E6uh2m1FP4kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LJspUpoaVkkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def update(df):\n",
        "\n",
        "    t = 100  # 기준값, 조건에 맞는 값은 \"noise\"로 대체\n",
        "    # 범주형 변수 리스트\n",
        "    cat_c = ['brand', 'model', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
        "    # 빈도수를 기준으로 대체\n",
        "    re_ = ['model', 'engine', 'transmission', 'ext_col', 'int_col']\n",
        "\n",
        "    # re_에 포함된 열의 빈도수(value_count) series 모형에서 100미만 값들을 noise로 대체\n",
        "    for col in re_:\n",
        "        df.loc[df[col].value_counts(dropna=False)[df[col]].values < t, col] = \"noise\"\n",
        "    # na 값은 missing으로 이후 타입을 category로 변경\n",
        "    for col in cat_c:\n",
        "        df[col] = df[col].fillna('missing')\n",
        "        df[col] = df[col].astype('category')\n",
        "\n",
        "    return df\n",
        "\n",
        "train  = update(train)\n",
        "test   = update(test)\n",
        "#각 행마다 해당 값의 출현 빈도를 기준으로 새로운 특성을 생성할 때 사용.\n",
        "print(train['model'].value_counts(dropna=False)[train['model']])\n",
        "X = train.drop('price', axis=1)\n",
        "y = train['price']"
      ],
      "metadata": {
        "id": "AATL1HDSSCzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)"
      ],
      "metadata": {
        "id": "CBHyib90d2tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#그냥 특정 열의 값 빈도수만 계산\n",
        "print(train['model'].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "HE19yF2fdQo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "# LightGBM의 콜백 함수 설정 (학습 로깅과 조기 종료 조건)\n",
        "callbacks = [log_evaluation(period=300), early_stopping(stopping_rounds=200)] # 300번마다 학습을 주기적으로 체크하겠다 200번동안 개선되지않으면 중단하겠다\n",
        "# 모든 범주형 열 리스트화\n",
        "cat_cols = train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "print(f\"cat_cols--------{cat_cols}\")\n",
        "\n",
        "# 교차 검증과 OOF 예측을 통해 MAE 또는 MSE를 계산하는 함수 정의\n",
        "def get_MAE_oof(df, target, lgb_params, cat_params=None, model_type='LGBM'):\n",
        "\n",
        "    # 초기 설정\n",
        "    oof_predictions = np.zeros(len(df))\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=1)  # 5개의 Fold로 분할\n",
        "    models = [] # 모델을 저장할 리스트\n",
        "    rmse_scores = [] # RMSE 점수를 저장할 리스트\n",
        "    # K-Fold 교차 검증\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(df)): # kf.split()을 쓰면 몇번 fold인지와 뭘 쪼갰는지train, val의 각인덱스를 출력한다\n",
        "\n",
        "        print(f\"Training fold {fold + 1}/{5} with {model_type}\")\n",
        "        # 훈련/검증 데이터 분리\n",
        "        X_train, X_val = df.iloc[train_idx], df.iloc[val_idx]\n",
        "        y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]\n",
        "        # LightGBM\n",
        "        if model_type == 'LGBM':\n",
        "            train_data = lgb.Dataset(X_train, label=y_train) #Dataet 메소드\n",
        "            val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
        "\n",
        "            model = lgb.train(\n",
        "                lgb_params,\n",
        "                train_data,\n",
        "                valid_sets=[train_data, val_data],\n",
        "                valid_names=['train', 'valid'],\n",
        "                callbacks=callbacks\n",
        "            )\n",
        "        # CatBoost # 범주형 변수 특화모델 Pool 이라는 객체가 범주형 변수를 자동으로 최적화 처리\n",
        "        elif model_type == 'CAT':\n",
        "            train_data = Pool(data=X_train, label=y_train , cat_features=cat_cols) #범주형 변수 이름이나 인덱스를 위 모든 범주형 변수 리스트로 지정\n",
        "            val_data = Pool(data=X_val, label=y_val , cat_features=cat_cols)\n",
        "\n",
        "            model = CatBoostRegressor(**cat_params)#unpacking 딕셔너리 형태로 저장한 파라미터를 언패킹하여 보다 간결한 코드로 전달\n",
        "            model.fit(train_data, eval_set=val_data, verbose=150, early_stopping_rounds=200) #log_evaluation는 훈련손실 검증손실과 verbose는 손실함수 기록\n",
        "        #두 모델 같이 저장 앙상블\n",
        "        models.append(model)\n",
        "        # 검증 데이터 예측\n",
        "        if model_type == 'LGBM':\n",
        "            pred = model.predict(X_val, num_iteration=model.best_iteration)# 최고성능을 낸 반복 early stopping과 함께사용해야한다\n",
        "        elif model_type == 'CAT':\n",
        "            pred = model.predict(X_val)\n",
        "\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
        "        rmse_scores.append(rmse)\n",
        "\n",
        "        print(f'{model_type} Fold RMSE: {rmse}')\n",
        "\n",
        "        oof_predictions[val_idx] = pred #Out-of-Fold 예측이라고 하며 각 폴드별로 train,val을 나눴으면 예시 폴드 5개이며 train 9개 val1개로 나눴을때 5폴드로나온 5개의 val가 oof_prediction에 val_idx에 들어가서\n",
        "\n",
        "    print(f'Mean RMSE: {np.mean(rmse_scores)}')\n",
        "    return oof_predictions, models\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "lgb_params = {\n",
        "    'objective': 'MAE',\n",
        "    'n_estimators': 1000,\n",
        "    'random_state': 1,\n",
        "}\n",
        "\n",
        "oof_predictions_lgbm, models_lgbm = get_MAE_oof(X, y, lgb_params, model_type='LGBM')\n",
        "X['LGBM_MAE'] = oof_predictions_lgbm\n",
        "\n",
        "\n",
        "LGBM_preds = np.zeros(len(test))\n",
        "for model in models_lgbm:#각 모델의 예측값을 모델 개수로 나누어 평균을 구합니다.\n",
        "# 이렇게 함으로써 여러 앙상블 모델의 예측 결과의 평균을 구함으로써 보다안정된 결과를 얻을수잇음\n",
        "    LGBM_preds += model.predict(test) / len(models_lgbm)\n",
        "test['LGBM_MAE'] = LGBM_preds\n",
        "\n",
        "\n",
        "\n",
        "lgb_params = {\n",
        "    'objective': 'MSE',\n",
        "    'n_estimators': 1000,\n",
        "    'random_state': 1,\n",
        "}\n",
        "\n",
        "oof_predictions_lgbm, models_lgbm = get_MAE_oof(X, y, lgb_params, model_type='LGBM')\n",
        "\n",
        "X['LGBM_MSE_diff'] = oof_predictions_lgbm - X['LGBM_MAE']\n",
        "\n",
        "\n",
        "LGBM_preds = np.zeros(len(test))\n",
        "for model in models_lgbm:\n",
        "    LGBM_preds += model.predict(test) / len(models_lgbm)\n",
        "test['LGBM_MSE_diff'] = LGBM_preds - test['LGBM_MAE']\n",
        "\n",
        "test.head()"
      ],
      "metadata": {
        "id": "NCA61wOwSGUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X['price'] = y\n",
        "#이게 autogluon 알아서 뚝딱딱\n",
        "predictor = TabularPredictor(label='price',\n",
        "                            eval_metric='rmse',\n",
        "                            problem_type='regression').fit(X,\n",
        "                                                       presets='best_quality',\n",
        "                                                       time_limit=3600*1,\n",
        "                                                       verbosity=2,\n",
        "                                                       num_gpus=0,\n",
        "                                                       included_model_types=['GBM', 'CAT']\n",
        "                                                      )\n",
        "y_pred = predictor.predict(test)\n",
        "\n",
        "# A bit of blending with the solution already blended from kagglers. Can be tweaked (currently 50/50).\n",
        "sub_blend = pd.read_csv('/kaggle/input/top-5-blended-car-prices/submission_9.csv')\n",
        "sample_sub = pd.read_csv('/kaggle/input/playground-series-s4e9/sample_submission.csv')\n",
        "sample_sub['price'] =  y_pred * 0.55 + sub_blend['price'] * 0.45\n",
        "sample_sub.to_csv(\"submission.csv\", index=False)\n",
        "sample_sub.head()\n",
        "#Autogluon 참고 링크\n",
        "#https://familia-89.tistory.com/77\n"
      ],
      "metadata": {
        "id": "ESCqUIWQqjxW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}